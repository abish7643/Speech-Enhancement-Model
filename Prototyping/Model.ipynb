{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function # whole point of from __future__ import print_function; to bring the print function from Python 3 into Python 2.6+.\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "from keras.constraints import min_max_norm\n",
    "import h5py\n",
    "\n",
    "from keras.constraints import Constraint\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.42\n",
    "#set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "with h5py.File('training.h5', 'r') as hf:\n",
    "    all_data = hf['data'][:]\n",
    "print('done.')\n",
    "\n",
    "window_size = 2000\n",
    "nb_sequences = len(all_data)//window_size\n",
    "print(nb_sequences, ' sequences')\n",
    "\n",
    "x_train = all_data[:nb_sequences*window_size, :42]\n",
    "x_train = np.reshape(x_train, (nb_sequences, window_size, 42))\n",
    "\n",
    "y_train = np.copy(all_data[:nb_sequences*window_size, 42:64])\n",
    "y_train = np.reshape(y_train, (nb_sequences, window_size, 22))\n",
    "\n",
    "noise_train = np.copy(all_data[:nb_sequences*window_size, 64:86])\n",
    "noise_train = np.reshape(noise_train, (nb_sequences, window_size, 22))\n",
    "\n",
    "vad_train = np.copy(all_data[:nb_sequences*window_size, 86:87])\n",
    "vad_train = np.reshape(vad_train, (nb_sequences, window_size, 1))\n",
    "\n",
    "all_data = 0;\n",
    "#x_train = x_train.astype('float32')\n",
    "#y_train = y_train.astype('float32')\n",
    "\n",
    "print(len(x_train), 'train sequences. x shape =', x_train.shape, 'y shape = ', y_train.shape)\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, [y_train, vad_train],\n",
    "          batch_size=batch_size,\n",
    "          epochs=40,\n",
    "          validation_split=0.1)\n",
    "model.save(\"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\n",
    "def my_crossentropy(y_true, y_pred):\n",
    "    return K.mean(2*K.abs(y_true-0.5) * K.binary_crossentropy(y_pred, y_true), axis=-1)\n",
    "\n",
    "def mymask(y_true):\n",
    "    return K.minimum(y_true+1., 1.)\n",
    "\n",
    "# def msse(y_true, y_pred):\n",
    "#     return K.mean(mymask(y_true) * K.square(K.sqrt(y_pred) - K.sqrt(y_true)), axis=-1)\n",
    "\n",
    "def mmse(y_true, y_pred):\n",
    "    return k.mean(sqrt(y_true)-k.sqrt(y_pred),axis=-1)\n",
    "\n",
    "def mycost(y_true, y_pred):\n",
    "    return K.mean(mymask(y_true) * (10*K.square(K.square(K.sqrt(y_pred) - K.sqrt(y_true))) + K.square(K.sqrt(y_pred) - K.sqrt(y_true)) + 0.01*K.binary_crossentropy(y_pred, y_true)), axis=-1)\n",
    "\n",
    "def my_accuracy(y_true, y_pred):\n",
    "    return K.mean(2*K.abs(y_true-0.5) * K.equal(y_true, K.round(y_pred)), axis=-1)\n",
    "\n",
    "class WeightClip(Constraint):\n",
    "    '''Clips the weights incident to each hidden unit to be inside a range\n",
    "    '''\n",
    "    def __init__(self, c=2):\n",
    "        self.c = c\n",
    "\n",
    "    def __call__(self, p):\n",
    "        return K.clip(p, -self.c, self.c)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'name': self.__class__.__name__,\n",
    "            'c': self.c}\n",
    "\n",
    "reg = 0.000001\n",
    "constraint = WeightClip(0.499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "\n",
    "main_input = Input(shape=(None, 42), name='main_input')\n",
    "\n",
    "dense_1 = Dense(24, activation='tanh', name='input_dense', kernel_constraint=constraint, bias_constraint=constraint)(main_input)\n",
    "\n",
    "gru_1 = GRU(24, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, name='gru_1', kernel_regularizer=regularizers.l2(reg), recurrent_regularizer=regularizers.l2(reg), kernel_constraint=constraint, recurrent_constraint=constraint, bias_constraint=constraint)(dense_1)\n",
    "\n",
    "noise_input = keras.layers.concatenate([dense_1, gru_1, main_input])\n",
    "\n",
    "gru_2 = GRU(48, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, name='gru_2', kernel_regularizer=regularizers.l2(reg), recurrent_regularizer=regularizers.l2(reg), kernel_constraint=constraint, recurrent_constraint=constraint, bias_constraint=constraint)(noise_input)\n",
    "\n",
    "denoise_input = keras.layers.concatenate([gru_1, gru_2, main_input])\n",
    "\n",
    "gru_3 = GRU(96, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, name='gru_3', kernel_regularizer=regularizers.l2(reg), recurrent_regularizer=regularizers.l2(reg), kernel_constraint=constraint, recurrent_constraint=constraint, bias_constraint=constraint)(denoise_input)\n",
    "\n",
    "dense_2 = Dense(22, activation='sigmoid', name='dense_2', kernel_constraint=constraint, bias_constraint=constraint)(gru_3)\n",
    "\n",
    "final_output = Dense(22, activation='softmax', name='final_output', kernel_constraint=constraint, bias_constraint=constraint)(dense_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=main_input, outputs=final_output)\n",
    "\n",
    "model.compile(loss=[mycost, my_crossentropy],\n",
    "              metrics=[mmse],\n",
    "              optimizer='adam', loss_weights=[10, 0.5])\n",
    "\n",
    "model.summary() #to get details of layers and parameters\n",
    "\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(lr=learning_rate, decay=decay_) if required to set particular learning rates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}